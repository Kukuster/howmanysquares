=== Plan A ===

1.  remove noise.
preferebly, it is a smart blur. How does smart blur work? First you get edges in white, presumably by Image.edge(int radius_pixels) function. Save that image aside (Image_edges).
then you go, maybe several times, with strong even blur kernel through the picture. But smartly:
1) Whenever the everblur kernel spans through the regions which are (almost) black on the Image_edges, do apply the kernel as usually.
2) Whenever the everblur kernel covers an edge (white stuff in Image_edges), ignore all pixels on and behind the edges making them zero in the kernel.

2. detect thick edges
???


......


=== Plan B ===
If thick edges that i try to detect are simply of one color....
then i don't actually need to detect those edges. Huh
Or do i?

1. very strong smart blur

???




=== Plan C ===

Try to do it first with already well processed image.
Make few images, like processing steps, and begin with the most processed, then proceed back to implement automatic processing up to from the original picture.


n. implement squares counting for straight lines with angles 0 and 90 degrees (+-1 degree)


n+1. implement the same stuff, but also for all different angles at the same time.
I think, I wiil group lines with different angles with something like K nearest neighbours with +- 1 degree.
But afaik i have to decide what will be the number of groups.
For this, i think i simply check all the angles of all the lines on the picture to decide how many groups i can possibly have.





=== Plan D ===

--- 1. Smart blur ---
1.1 Get edges in white, presumably by Image.edge(int radius_pixels) function. Save that image aside (Image_edges).
1.2 kernel convolution (loop):
then you go, maybe several times, with strong even blur kernel through the picture. But smartly, i.e.
    Whenever the everblur kernel: 
        spans through the region which is all (almost) black on the Image_edges,
            apply the kernel as usually.
        covers an edge (white stuff in Image_edges),
            ignore all pixels on and behind the edges making them zero in the kernel.
Repeat 1.2 . If necessary, repeat 1.1+1.2 , or optimize with edge detection with hyisteresis thresholding in order to avoid long execution time.

2. ??? make thick edges thin

3. 
input: image with thin (1-2 px wide) edges with color hue encoding angle of edges.
For now assuming hue from 0 to 360 maps to the value of angle U[0;180).
Probably i would like to have it in float, but if there's only 360 possible values obtainable from RGB.
Also its not that accurate: http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MARBLE/low/edges/gradient.htm
<< In terms of accuracy, the Sobel operator may give an edge magnitude value to within 7% and an edge angle magnitude to within 2 degrees,
ignoring the effects of quantisation errors, edge displacement from the centre of the pixel, electronic noise etc. >>
Sounds like not very good deal, but lets try anyway...




=== Plan E ===
- get fucking kuklog work in KukMagick
- get KukMagick::Image::kukConvolve() work
- try different values of kernel_sum to make kukConvolve() work with laplacian edges. Ask how is convolve normalized on GraphicsMagick forum.
- If figured out how to edge detection manially properly, do smartBlur in one iteration through pixels
- try to do my square detection from this


--- 2020.03.20
At least, it compiles now. But now outputs some Magick++ runtime "segmentation" error.
First I have to verify kuklog works in all scopes, then try to fix that Magick++ error.








=== notes ===
Sobel edge detection, according to Computerphile, works only for a single channel.
Probably, if working with color (if also need edges with change in color but no change in intensity), then one can try to do sobel on each of 3 RGB channels.

--- 1. Edge detection kernel normalization ---
Having an y edge detector kernel
 1  2  1
 0  0  0
-1 -2 -1
Assuming white is 1, black is 0. When this kernel encounters straight horizontal edge from pure white to pure black, here's the calculated value:
(1*1 + 2*1 + 1*1) - (-1*0 + -2*0 + -1*0) = 4, which is 4 times more than maximum value for color intensity ([0;1]), and is the strongest possible edge.
For nonHDRI, such values more than 1 get clipped to 1.

To normalize calculated values to span properly on [0;1], divide by half sum of absolute kernel values, i.e.:
k = (|1|+|2|+|1|+|-1|+|-2|+|-1|)/2 = 8/2 = 4
And get normalized kernel:
 0.25  0.50  0.25
  0     0     0
-0.25 -0.50 -0.25

This formula holds only for kernels which elements sum to 0.


--- 2. An issue with Mean XY edges ---
Mean XY edges is an edge extraction in which images of Gx and Gy (by Sobel kernel convolution edge extraction) are multiplied by 1/2 and added together in one image.

Take a look at "volumes/output/51_1580131676_01_edges_xyMean.jpg"
This is how Mean XY edges process original image. Square sides are screwed up.

Take a look at "volumes/output/51_1580131641_preprocessed_01_edges_xyMean.jpg"
This is how Mean XY edges process preprocessed image with small edges (I did "Maximize" in Photoshop, check "volumes/input/51_steps_processing/51_maximize.jpg")

Not only this doesn't give angle of a side, it also highly screws up sides.


--- 3. Edges detection issue with color ---
Most of edge detection techniques don't consider actual change in color, instead, they account for change in color intensity, which is brightness, and is calculated by the formula:
B=max(R,G,B)
But i have to deal with actual color change. How to calculate it properly?
First i thought i get each channel separately, convert them to grayscale image:
I - input image, R - read channel, E(image) - returns edges image
I = (I.R, I.G, I.B)
let IR = (I.R, I.R, I.R), IG = (I.G, I.G, I.G), IB = (I.B, I.B, I.B)    // grayscale
let ER = E(IR), EG = E(IG), EB = E(IB)      // grayscale
let EI = ER + EG + EB

But because ER,EG,EB already span [0,255], it will give 255 color quants difference between f.e. (85,170,84) & (170,84,169), or (85,43,128) & (42,171,171), which doesn't seem to be of the same value as between (0,0,0) & (255,255,255).
Also anyway this is wrong.
Weighting each channel with 1/3 is even more wierd, because difference between (0,0,0) and (255,0,0) will be considered low (85) and two times less than difference between (255,255,255) and (255,0,0), which would be .
Color intensity is equal for (0,127,0) and (0,127,63), because max(0,127,0)=max(0,127,63)=127, basically this is good measure of amount of color,
but its not calculated properly when comparing color intensities for edge detection, which treats (0,64,192) and (128,192,64) as no difference in color intensity.
what therefore we should measure instead, is not difference in color intensity, but color intensity of a difference:
not   E = |max(0,64,192) - max(128,192,64)| = 0  ,  but   E = max(|0-128|,|64-192|,|192-64|) = 128







=== Documentation ===
Convolve options:
1. normalize to range [0, MaxRGB]
overrides #2
2. take absolute value
overriden by #1
3. "fast":
    - ignores borders

